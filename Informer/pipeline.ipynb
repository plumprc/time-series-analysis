{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from data.data_loader import Dataset_ETT_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len, label_len, pred_len = 96, 48, 24\n",
    "\n",
    "data_set = Dataset_ETT_hour(\n",
    "    root_path='data/ETT',\n",
    "    data_path='ETTh1.csv',\n",
    "    size=[seq_len, label_len, pred_len],\n",
    "    features='M', # multivariate predict multivariate\n",
    "    freq='h' # ['month','day','weekday','hour'], data-agnostic\n",
    ")\n",
    "'''\n",
    "    seq_x and seq_y are overlapping!\n",
    "    len(seq_x) = seq_len + label_len\n",
    "    len(seq_y) = label_len + pred_len\n",
    "'''\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_x_mark, batch_y_mark = iter(data_loader).next()\n",
    "pred_seq = torch.zeros([batch_y.shape[0], pred_len, batch_y.shape[-1]]).float()\n",
    "pred_seq = torch.cat([batch_y[:,:label_len,:], pred_seq], dim=1).float()\n",
    "true = batch_y[:,-pred_len:,0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "# # (B, L, features) -> (B, L, d_models)\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__>='1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n",
    "                                    kernel_size=3, padding=padding, padding_mode='circular')\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1))\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4; hour_size = 24\n",
    "        weekday_size = 7; day_size = 32; month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n",
    "        if freq=='t':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        \n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        \n",
    "        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:,:,3])\n",
    "        weekday_x = self.weekday_embed(x[:,:,2])\n",
    "        day_x = self.day_embed(x[:,:,1])\n",
    "        month_x = self.month_embed(x[:,:,0])\n",
    "        \n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "# (B, L, freq) -> (B, L, d_model)\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n",
    "        \n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_in, dec_in, d_model, embed, freq, dropout = 7, 7, 512, 'TimeF', 'h', 0.05\n",
    "\n",
    "enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "enc_embd = enc_embedding(batch_x.float(), batch_x_mark.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.encoder import Encoder, EncoderLayer, ConvLayer\n",
    "from models.decoder import Decoder, DecoderLayer\n",
    "from models.attn import FullAttention, ProbAttention, AttentionLayer\n",
    "\n",
    "class Informer(nn.Module):\n",
    "    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n",
    "                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n",
    "                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n",
    "                output_attention = False, distil=True, mix=True,\n",
    "                device=torch.device('cuda:0')):\n",
    "        super(Informer, self).__init__()\n",
    "        self.pred_len = out_len\n",
    "        self.attn = attn\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "        # Data Embedding (B, L, feature) -> (B, L, d_model)\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "        # Attention\n",
    "        Attn = ProbAttention if attn=='prob' else FullAttention\n",
    "        # Encoder (B, seq_len, d_model) distil -> (B, seq_len / 4, d_model)\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n",
    "                                d_model, n_heads, mix=False),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            [\n",
    "                ConvLayer(\n",
    "                    d_model\n",
    "                ) for l in range(e_layers-1)\n",
    "            ] if distil else None,\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder (B, label_len + pred_len, d_model)\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n",
    "                                d_model, n_heads, mix=mix),\n",
    "                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n",
    "                                d_model, n_heads, mix=False),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "        \n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "        dec_out = self.projection(dec_out)\n",
    "        \n",
    "        if self.output_attention:\n",
    "            return dec_out[:,-self.pred_len:,:], attns\n",
    "        else:\n",
    "            return dec_out[:,-self.pred_len:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Informer(7, 7, 7, seq_len, label_len, pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(batch_x.float(), batch_x_mark.float(), pred_seq.float(), batch_y_mark.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
