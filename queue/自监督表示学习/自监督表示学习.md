推荐阅读：[Self-Supervised Representation Learning](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)

* Why: Self-supervised learning empowers us to exploit a variety of labels that come with the data for free
* Aim: Learn intermediate representation that can carry good semantic or structural meanings and can be beneficial to a variety of practical downstream tasks

## Image-Based
Some auxiliary tasks used in previous works：
1. Distortion (Transformation): The pretext task is to discriminate between a set of distorted images. (e.g. translation, rotation, scaling, etc.)

testest


2. Patches: The pretext task is to predict the relationship between multiple patches extracted from one image.

Notice that to avoid the model only catching low-level trivial signals, such as connecting a straight line across boundary or matching local patterns, we need additional noise to avert these shortcuts.
* Add gaps between patches
* Randomly downsample some patches and then upsampling it
* Randomly drop $2$ of $3$ color channels (chromatic aberration)

3. Colorization: The pretext task is to color a grayscale input image
4. Generative Modeling: The pretext task is to reconstruct the original input while learning meaningful latent representation

The design is inspired by the fact that humans can easily recognize objects in pictures even with noise, indicating that key visual features can be extracted and separated from noise. 

## Contrastive Learning

TODO: 来个自引，CPC

## Video-Based
A video contains a sequence of semantically related frames.

1. Tracking: tracking moving objects in videos to learn good representation of each frame based on negative sampling

2. Frame Sequence: validate frame order or predicting the arrow of time

3. Video Colorization: copy colors from a normal reference frame in color to another target frame in grayscale

